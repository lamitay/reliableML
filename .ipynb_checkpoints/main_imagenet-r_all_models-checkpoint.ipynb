{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da031a1-fdb3-48dc-855b-7df5f5f94bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "\n",
    "from dataloader import *\n",
    "from models import load_model\n",
    "from metrics import *\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "from preprocessing import preprocess_images_any_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1fbc6a6-71b5-4f29-98da-99794c8e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_labels():\n",
    "    \"\"\"\n",
    "    Fetches the ImageNet class labels from a JSON file hosted online.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of class labels where the index corresponds to the class ID in the ImageNet dataset.\n",
    "    \"\"\"\n",
    "    classes_text = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "    with urllib.request.urlopen(classes_text) as url:\n",
    "        imagenet_labels = json.loads(url.read().decode())\n",
    "    return imagenet_labels\n",
    "\n",
    "\n",
    "# Register hook to capture the model's embeddings\n",
    "def get_embedding_hook(batch_idx, batch_size, embed_dir):\n",
    "    \"\"\"\n",
    "    Creates and returns a hook function to capture and save the model's embeddings.\n",
    "\n",
    "    Returns:\n",
    "        function: A hook function that can be registered to a PyTorch nn.Module.\n",
    "    \"\"\"\n",
    "    def hook(module, input, output):\n",
    "        output = output.detach().cpu().numpy()\n",
    "        for i in range(output.shape[0]):\n",
    "            # Calculate the overall index of the image in the dataset\n",
    "            image_idx = batch_idx * batch_size + i\n",
    "            np.save(os.path.join(embed_dir, f\"{image_idx}_embeddings.npy\"), output[i])\n",
    "    return hook\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define device, batch size and directory path for ImageNet validation set\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    data_name = 'imagenet-r'\n",
    "    in_Newton_flag = 'home' in os.getcwd()  # if it's true it means that I'm running the code on the server    \n",
    "    base_exp_dir = '/home/davidva/experiments_David' if in_Newton_flag else 'C:/Users/David/PycharmProjects/reliableML/experiments_David'\n",
    "    val_dir = '/home/davidva/datasets/imagenet-r' if in_Newton_flag else'E:/MLreliability_project/data/imagenet-r'\n",
    "    all_original_classes_flag = True if data_name in ['imagenet-r', 'imagenet', 'imagenet-sketch'] else False\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 128\n",
    "\n",
    "    # Load imagenet labels as real classes\n",
    "    imagenet_labels = load_imagenet_labels()  # 'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark'...\n",
    "\n",
    "    if data_name in ['imagenet', 'imagenet-v2', 'imagenet-sketch']:\n",
    "        ds_specific_mask = [True] * 1000\n",
    "        ds_specific_labels = imagenet_labels  # the classes of the specific dataset that we're working with\n",
    "    elif data_name == 'imagenet-r':\n",
    "        from class_names import imagenet_r_labels, imagenet_r_mask\n",
    "        ds_specific_r_mask = imagenet_r_mask\n",
    "        ds_specific_labels = imagenet_r_labels\n",
    "    elif data_name == 'imagenet-a':\n",
    "        from class_names import imagenet_a_labels, imagenet_a_mask\n",
    "        ds_specific_mask = imagenet_a_mask\n",
    "        ds_specific_labels = imagenet_a_labels\n",
    "        \n",
    "    model_names = ['resnet50', 'resnet18', 'resnet34', 'resnet101', 'resnet152', 'vgg16', 'vgg19', 'alexnet', 'resnext', 'wide_resnet', 'densenet121', 'googlenet', 'mobilenet_v2']\n",
    "    # model_names = ['googlenet', 'mobilenet_v2']\n",
    "\n",
    "    for model_name in model_names:\n",
    "        # Experiment name\n",
    "        curr_time = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "        exp_base_name = 'predict_' + data_name + '_' + model_name\n",
    "        exp_name = exp_base_name + '_' + curr_time\n",
    "        exp_dir = os.path.join(base_exp_dir, exp_name)\n",
    "        results_dir = os.path.join(exp_dir, 'results')\n",
    "        embed_dir = os.path.join(results_dir, 'val_embeddings')\n",
    "    \n",
    "        # Create experiment directory\n",
    "        os.makedirs(exp_dir, exist_ok=True)\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        os.makedirs(embed_dir, exist_ok=True)\n",
    "            \n",
    "        # Load the ImageNet validation dataset with defined transformations\n",
    "        val_dataset = ImageFolder(val_dir, transform=preprocess_images_any_dataset(model_name))\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=5)\n",
    "\n",
    "        # Load model\n",
    "        model = load_model(model_name).to(device)\n",
    "        \n",
    "        # Register the hook at the penultimate layer of the model\n",
    "        if model_name in ['densenet121', 'mobilenet_v2']:\n",
    "            layer = model.features  # TODO is it correct?\n",
    "        else:\n",
    "            layer = model.avgpool\n",
    "        \n",
    "        # Prepare DataFrame to store results\n",
    "        results = []\n",
    "        total_correct = 0\n",
    "        batch_num = 0\n",
    "        all_entropies = np.empty([0])\n",
    "        \n",
    "        # Disable gradients for faster inference\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, labels) in enumerate(tqdm(val_loader, desc=f\"Processing {exp_name}\")):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                handle = layer.register_forward_hook(get_embedding_hook(batch_idx, batch_size, embed_dir))\n",
    "\n",
    "                # Run forward pass through the model and calculate probabilities\n",
    "                output = model(images)\n",
    "                probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "                probabilities = probabilities * torch.tensor(imagenet_r_mask).to(device)  # using only the classes that are in both datasets\n",
    "    \n",
    "                # Get top-5 predictions and confidences\n",
    "                top5_prob, top5_classes = torch.topk(probabilities, 5)\n",
    "                entropies = scipy.stats.entropy(probabilities.detach().cpu().numpy(), axis=1)\n",
    "                all_entropies = np.concatenate((all_entropies, entropies))  # might be really wasteful in terms of run time\n",
    "\n",
    "                # # Iterate over each image in the batch\n",
    "                # for i in range(len(images)):\n",
    "                #     image_path = val_dataset.imgs[i][0]\n",
    "                #     true_class = val_dataset.classes[labels[i].item()]\n",
    "                #     predictions = {\"image_path\": image_path, \"true_class\": true_class}\n",
    "                #     for j in range(5):\n",
    "                #         predictions[f\"top{j + 1}_prediction_class\"] = val_dataset.classes[top5_classes[i, j].item()]\n",
    "                #         predictions[f\"top{j + 1}_confidence\"] = top5_prob[i, j].item()\n",
    "                #     results.append(predictions)\n",
    "    \n",
    "                # Iterate over each image in the batch\n",
    "                for i in range(len(images)):\n",
    "                    image_idx = batch_idx * batch_size + i\n",
    "                    image_path = val_dataset.imgs[i + batch_num * batch_size][0]\n",
    "                    # true_class = val_dataset.classes[labels[i].item()]\n",
    "                    true_class = ds_specific_labels[labels[i].item()]  # e.g. labels[i].item()=0. true_class=goldfish\n",
    "                    return\n",
    "                    predictions = {\"image_path\": image_path,\n",
    "                                   \"true_class\": true_class,\n",
    "                                   \"embeddings_path\":  os.path.join(embed_dir, f\"{image_idx}_embeddings.npy\")}\n",
    "                    \n",
    "                    for j in range(5):\n",
    "                        # predictions[f\"top{j+1}_prediction_class\"] = val_dataset.classes[top5_classes[i, j].item()]\n",
    "                        prediction_class = imagenet_labels[top5_classes[i, j].item()]\n",
    "                        predictions[f\"top{j+1}_prediction_class\"] = prediction_class\n",
    "                        predictions[f\"top{j+1}_confidence\"] = top5_prob[i, j].item()\n",
    "    \n",
    "                        # Check if top-1 prediction is correct\n",
    "                        if j == 0 and prediction_class == true_class:\n",
    "                            total_correct += 1\n",
    "                    results.append(predictions)\n",
    "                batch_num += 1\n",
    "                handle.remove()  # Unregister the hook after processing the batch\n",
    "        \n",
    "        # Convert results to DataFrame and save to CSV\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(results_dir, f\"full_val_predictions_{exp_base_name}.csv\"), index=False)\n",
    "    \n",
    "        # Calculate average and std of the top1 confidences across the val set2\n",
    "        avg_confidence = results_df[\"top1_confidence\"].mean()\n",
    "        std_confidence = results_df[\"top1_confidence\"].std()\n",
    "        accuracy = total_correct / len(val_dataset)\n",
    "        average_entropy = np.mean(all_entropies)\n",
    "        \n",
    "        # Save average and std confidences in a new DataFrame\n",
    "        confidence_df = pd.DataFrame({\n",
    "            \"Accuracy\": [accuracy],\n",
    "            \"Average Confidence\": [avg_confidence],\n",
    "            \"Standard Deviation Confidence\": [std_confidence],\n",
    "            \"Average Entropy\": [average_entropy]\n",
    "        })\n",
    "        confidence_df.to_csv(os.path.join(results_dir, f\"val_confidence_summary_{exp_base_name}.csv\"), index=False)\n",
    "\n",
    "        # Handle embeddings\n",
    "        embeddings = np.array([np.load(file) for file in results_df['embeddings_path']])\n",
    "        # assuming embeddings is a 4D numpy array\n",
    "        embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "        average, covariance = calculate_activation_statistics(embeddings)\n",
    "        np.save(os.path.join(results_dir, 'embeddings_covariance.npy'), covariance)\n",
    "        np.save(os.path.join(results_dir, 'embeddings_average.npy'), average)\n",
    "        # np.save(os.path.join(results_dir, 'tot_embeddings_2D_np_array.npy'), embeddings)\n",
    "        \n",
    "        # Create a new DataFrame for embeddings\n",
    "        # df_embeddings = pd.DataFrame(*******, columns=np.arange(0, embeddings.shape[1]))\n",
    "        # df_embeddings['true_class'] = results_df['true_class']\n",
    "        # df_embeddings['predicted_class'] = results_df['top1_prediction_class']\n",
    "        # df_embeddings['image_path'] = results_df['image_path']\n",
    "        # # Save as CSV\n",
    "        # df_embeddings.to_csv(os.path.join(results_dir, f\"val_embeddings_2d_{exp_base_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51cb8608-441b-4b3c-8048-daebe08d39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing predict_imagenet-r_resnet50_18-07-2023_13-57-22:   0%|                         | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "goldfish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing predict_imagenet-r_resnet50_18-07-2023_13-57-22:   0%|                         | 0/235 [00:15<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb79cdb5-850e-4f96-9fe3-7eb11e7c41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 avgpool fc\n",
      "resnet18 avgpool fc\n",
      "resnet34 avgpool fc\n",
      "resnet101 avgpool fc\n",
      "resnet152 avgpool fc\n",
      "vgg16 avgpool classifier\n",
      "vgg19 avgpool classifier\n",
      "alexnet avgpool classifier\n",
      "resnext avgpool fc\n",
      "wide_resnet avgpool fc\n",
      "densenet121 features classifier\n",
      "googlenet dropout fc\n",
      "mobilenet_v2 features classifier\n"
     ]
    }
   ],
   "source": [
    "# for layer in k.children():\n",
    "#     print(layer)\n",
    "\n",
    "model_names = ['resnet50', 'resnet18', 'resnet34', 'resnet101', 'resnet152', 'vgg16', 'vgg19', 'alexnet', 'resnext', 'wide_resnet', 'densenet121', 'googlenet', 'mobilenet_v2']\n",
    "\n",
    "for model_name in model_names:\n",
    "    k = load_model(model_name)\n",
    "    layers_list = []\n",
    "    for name, _ in k.named_children():\n",
    "        if not name.startswith('params'):\n",
    "            layers_list.append(name)\n",
    "    \n",
    "    print(model_name, layers_list[-2], layers_list[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a18a751-5298-459b-8db5-d31c9fb71041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(load_model('vgg16'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
