{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da031a1-fdb3-48dc-855b-7df5f5f94bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "\n",
    "from dataloader import *\n",
    "from models import load_model\n",
    "from metrics import *\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import class_names\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "from preprocessing import preprocess_images_any_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fbc6a6-71b5-4f29-98da-99794c8e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagenet_labels():\n",
    "    \"\"\"\n",
    "    Fetches the ImageNet class labels from a JSON file hosted online.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of class labels where the index corresponds to the class ID in the ImageNet dataset.\n",
    "    \"\"\"\n",
    "    classes_text = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
    "    with urllib.request.urlopen(classes_text) as url:\n",
    "        imagenet_labels = json.loads(url.read().decode())\n",
    "    return imagenet_labels\n",
    "\n",
    "\n",
    "# Register hook to capture the model's embeddings\n",
    "def get_embedding_hook(batch_idx, batch_size, embed_dir):\n",
    "    \"\"\"\n",
    "    Creates and returns a hook function to capture and save the model's embeddings.\n",
    "\n",
    "    Returns:\n",
    "        function: A hook function that can be registered to a PyTorch nn.Module.\n",
    "    \"\"\"\n",
    "    def hook(module, input, output):\n",
    "        output = output.detach().cpu().numpy()\n",
    "        for i in range(output.shape[0]):\n",
    "            # Calculate the overall index of the image in the dataset\n",
    "            image_idx = batch_idx * batch_size + i\n",
    "            np.save(os.path.join(embed_dir, f\"{image_idx}_embeddings.npy\"), output[i])\n",
    "    return hook\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Define device, batch size and directory path for ImageNet validation set\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    data_name = 'imagenet-a'\n",
    "    base_exp_dir = '/home/davidva/experiments_David'\n",
    "    val_dir = '/home/davidva/datasets/imagenet-a'\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 128\n",
    "\n",
    "    # Load imagenet labels as real classes\n",
    "    imagenet_labels = load_imagenet_labels()  # 'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark'...\n",
    "\n",
    "    if data_name in ['imagenet', 'imagenet-v2', 'imagenet-sketch']:\n",
    "        ds_specific_mask = [True] * 1000\n",
    "        ds_specific_labels = imagenet_labels  # the classes of the specific dataset that we're working with\n",
    "    elif data_name == 'imagenet-r':\n",
    "        ds_specific_r_mask = class_names.imagenet_r_mask\n",
    "        ds_specific_labels = class_names.imagenet_r_labels\n",
    "    elif data_name == 'imagenet-a':  # note: if the hidden file .ipynb_checkpoints is inside of the folder of the imagenet-a data,\n",
    "                                     # it should be removed from there in order to create the DataFolder object\n",
    "        ds_specific_mask = class_names.imagenet_a_mask\n",
    "        ds_specific_labels = class_names.imagenet_a_labels\n",
    "        \n",
    "    model_names = ['resnet50', 'resnet18', 'resnet34', 'resnet101', 'resnet152', 'vgg16', 'vgg19', 'alexnet', 'resnext', 'wide_resnet', 'densenet121', 'googlenet', 'mobilenet_v2']\n",
    "    # model_names = ['googlenet', 'mobilenet_v2']\n",
    "\n",
    "    for model_name in model_names:\n",
    "        # Experiment name\n",
    "        curr_time = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "        exp_base_name = 'predict_' + data_name + '_' + model_name\n",
    "        exp_name = exp_base_name + '_' + curr_time\n",
    "        exp_dir = os.path.join(base_exp_dir, exp_name)\n",
    "        results_dir = os.path.join(exp_dir, 'results')\n",
    "        embed_dir = os.path.join(results_dir, 'val_embeddings')\n",
    "    \n",
    "        # Create experiment directory\n",
    "        os.makedirs(exp_dir, exist_ok=True)\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        os.makedirs(embed_dir, exist_ok=True)\n",
    "            \n",
    "        # Load the ImageNet validation dataset with defined transformations\n",
    "        val_dataset = ImageFolder(val_dir, transform=preprocess_images_any_dataset(model_name))\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=5)\n",
    "\n",
    "        # Load model\n",
    "        model = load_model(model_name).to(device)\n",
    "        \n",
    "        # Register the hook at the penultimate layer of the model\n",
    "        if model_name in ['densenet121', 'mobilenet_v2']:\n",
    "            layer = model.features  # TODO is it correct?\n",
    "        else:\n",
    "            layer = model.avgpool\n",
    "        \n",
    "        # Prepare DataFrame to store results\n",
    "        results = []\n",
    "        total_correct = 0\n",
    "        batch_num = 0\n",
    "        all_entropies = np.empty([0])\n",
    "        \n",
    "        # Disable gradients for faster inference\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, labels) in enumerate(tqdm(val_loader, desc=f\"Processing {exp_name}\")):\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                handle = layer.register_forward_hook(get_embedding_hook(batch_idx, batch_size, embed_dir))\n",
    "\n",
    "                # Run forward pass through the model and calculate probabilities\n",
    "                output = model(images)\n",
    "                probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "                probabilities = probabilities * torch.tensor(ds_specific_mask).to(device)  # using only the classes that are in both datasets\n",
    "    \n",
    "                # Get top-5 predictions and confidences\n",
    "                top5_prob, top5_classes = torch.topk(probabilities, 5)\n",
    "                entropies = scipy.stats.entropy(probabilities.detach().cpu().numpy(), axis=1)\n",
    "                all_entropies = np.concatenate((all_entropies, entropies))  # might be really wasteful in terms of run time\n",
    "\n",
    "                # # Iterate over each image in the batch\n",
    "                # for i in range(len(images)):\n",
    "                #     image_path = val_dataset.imgs[i][0]\n",
    "                #     true_class = val_dataset.classes[labels[i].item()]\n",
    "                #     predictions = {\"image_path\": image_path, \"true_class\": true_class}\n",
    "                #     for j in range(5):\n",
    "                #         predictions[f\"top{j + 1}_prediction_class\"] = val_dataset.classes[top5_classes[i, j].item()]\n",
    "                #         predictions[f\"top{j + 1}_confidence\"] = top5_prob[i, j].item()\n",
    "                #     results.append(predictions)\n",
    "    \n",
    "                # Iterate over each image in the batch\n",
    "                for i in range(len(images)):\n",
    "                    image_idx = batch_idx * batch_size + i\n",
    "                    image_path = val_dataset.imgs[i + batch_num * batch_size][0]\n",
    "                    # true_class = val_dataset.classes[labels[i].item()]\n",
    "                    true_class = ds_specific_labels[labels[i].item()]  # e.g. labels[i].item()=0. true_class=goldfish\n",
    "                    predictions = {\"image_path\": image_path,\n",
    "                                   \"true_class\": true_class,\n",
    "                                   \"embeddings_path\":  os.path.join(embed_dir, f\"{image_idx}_embeddings.npy\")}\n",
    "                    \n",
    "                    for j in range(5):\n",
    "                        # predictions[f\"top{j+1}_prediction_class\"] = val_dataset.classes[top5_classes[i, j].item()]\n",
    "                        prediction_class = imagenet_labels[top5_classes[i, j].item()]\n",
    "                        predictions[f\"top{j+1}_prediction_class\"] = prediction_class\n",
    "                        predictions[f\"top{j+1}_confidence\"] = top5_prob[i, j].item()\n",
    "    \n",
    "                        # Check if top-1 prediction is correct\n",
    "                        if j == 0 and prediction_class == true_class:\n",
    "                            total_correct += 1\n",
    "                    results.append(predictions)\n",
    "                batch_num += 1\n",
    "                handle.remove()  # Unregister the hook after processing the batch\n",
    "        \n",
    "        # Convert results to DataFrame and save to CSV\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(os.path.join(results_dir, f\"full_val_predictions_{exp_base_name}.csv\"), index=False)\n",
    "    \n",
    "        # Calculate average and std of the top1 confidences across the val set2\n",
    "        avg_confidence = results_df[\"top1_confidence\"].mean()\n",
    "        std_confidence = results_df[\"top1_confidence\"].std()\n",
    "        accuracy = total_correct / len(val_dataset)\n",
    "        average_entropy = np.mean(all_entropies)\n",
    "        \n",
    "        # Save average and std confidences in a new DataFrame\n",
    "        confidence_df = pd.DataFrame({\n",
    "            \"Accuracy\": [accuracy],\n",
    "            \"Average Confidence\": [avg_confidence],\n",
    "            \"Standard Deviation Confidence\": [std_confidence],\n",
    "            \"Average Entropy\": [average_entropy]\n",
    "        })\n",
    "        confidence_df.to_csv(os.path.join(results_dir, f\"val_confidence_summary_{exp_base_name}.csv\"), index=False)\n",
    "\n",
    "        # Handle embeddings\n",
    "        embeddings = np.array([np.load(file) for file in results_df['embeddings_path']])\n",
    "        # assuming embeddings is a 4D numpy array\n",
    "        embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "        average, covariance = calculate_activation_statistics(embeddings)\n",
    "        np.save(os.path.join(results_dir, 'embeddings_covariance.npy'), covariance)\n",
    "        np.save(os.path.join(results_dir, 'embeddings_average.npy'), average)\n",
    "        # np.save(os.path.join(results_dir, 'tot_embeddings_2D_np_array.npy'), embeddings)\n",
    "        \n",
    "        # Create a new DataFrame for embeddings\n",
    "        # df_embeddings = pd.DataFrame(*******, columns=np.arange(0, embeddings.shape[1]))\n",
    "        # df_embeddings['true_class'] = results_df['true_class']\n",
    "        # df_embeddings['predicted_class'] = results_df['top1_prediction_class']\n",
    "        # df_embeddings['image_path'] = results_df['image_path']\n",
    "        # # Save as CSV\n",
    "        # df_embeddings.to_csv(os.path.join(results_dir, f\"val_embeddings_2d_{exp_base_name}.csv\"), index=False)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51cb8608-441b-4b3c-8048-daebe08d39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing predict_imagenet-a_resnet50_18-07-2023_15-27-30: 100%|█████████████████| 59/59 [01:37<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb79cdb5-850e-4f96-9fe3-7eb11e7c41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 avgpool fc\n",
      "resnet18 avgpool fc\n",
      "resnet34 avgpool fc\n",
      "resnet101 avgpool fc\n",
      "resnet152 avgpool fc\n",
      "vgg16 avgpool classifier\n",
      "vgg19 avgpool classifier\n",
      "alexnet avgpool classifier\n",
      "resnext avgpool fc\n",
      "wide_resnet avgpool fc\n",
      "densenet121 features classifier\n",
      "googlenet dropout fc\n",
      "mobilenet_v2 features classifier\n"
     ]
    }
   ],
   "source": [
    "# for layer in k.children():\n",
    "#     print(layer)\n",
    "\n",
    "model_names = ['resnet50', 'resnet18', 'resnet34', 'resnet101', 'resnet152', 'vgg16', 'vgg19', 'alexnet', 'resnext', 'wide_resnet', 'densenet121', 'googlenet', 'mobilenet_v2']\n",
    "\n",
    "for model_name in model_names:\n",
    "    k = load_model(model_name)\n",
    "    layers_list = []\n",
    "    for name, _ in k.named_children():\n",
    "        if not name.startswith('params'):\n",
    "            layers_list.append(name)\n",
    "    \n",
    "    print(model_name, layers_list[-2], layers_list[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a18a751-5298-459b-8db5-d31c9fb71041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(load_model('mobilenet_v2'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
