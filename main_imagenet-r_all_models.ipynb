{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4da031a1-fdb3-48dc-855b-7df5f5f94bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "\n",
    "from dataloader import *\n",
    "from models import load_model\n",
    "from metrics import *\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "import class_names\n",
    "from utils import *\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "from preprocessing import preprocess_images_any_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc9c8aa7-e0d8-412d-b0e3-159f9bcb177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = os.listdir('/home/davidva/experiments_David')\n",
    "experiment_list.remove('.ipynb_checkpoints')\n",
    "header_exists_flag = 0  # indicates whether the combines CSV file has a header of \"Dataset, Model, Accuracy...\"\n",
    "# print(experiment_list)\n",
    "with open('/home/davidva/vscode_projects/reliableML/all_experiments.csv', 'w') as f:\n",
    "    wf = csv.writer(f, delimiter = ',')\n",
    "    for folder in experiment_list[4:]:\n",
    "        results_path = '/home/davidva/experiments_David/' + folder + '/results'\n",
    "        file_list = os.listdir(results_path)\n",
    "        end_of_data_name_index = folder.index('_')\n",
    "        with open(results_path + '/' + file_list[2], mode=\"r\") as csv_file:\n",
    "            reader = csv.reader(csv_file) #this is the reader object\n",
    "            line_count = 0\n",
    "            for row_num, row in enumerate(reader):\n",
    "                if header_exists_flag == 0 and row_num == 0:\n",
    "                    header_exists_flag = 1\n",
    "                    row = ['Dataset', 'Model'] + row\n",
    "                    wf.writerow(row)\n",
    "                if row_num == 1:\n",
    "                    sub_strings = folder.split('_')\n",
    "                    model_name = sub_strings[2] + '_resnet' if 'wide' in sub_strings[2] else sub_strings[2]\n",
    "                    data_name = sub_strings[1]\n",
    "                    row = [data_name, model_name] + row\n",
    "                    wf.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "472fa8b4-3507-4476-9edc-dc0ef0ee7e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n02419796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['n02422106', 'n02422699', 'n02423022']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('/home/davidva/datasets/imagenet_vid_ytbb_robust/imagenet-vid-robust/misc/imagenet_vid_class_index.json')\n",
    "vid_class_index = json.load(f)\n",
    "g = open('/home/davidva/datasets/imagenet_vid_ytbb_robust/imagenet-vid-robust/misc/rev_wnid_map.json')\n",
    "class_name_converter = json.load(g)\n",
    "ground_truth = str(1)\n",
    "input_to_class_name_converter = vid_class_index[ground_truth][0]\n",
    "print(input_to_class_name_converter)\n",
    "class_name_converter[input_to_class_name_converter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d7bf0cf-7762-4828-8cdc-229b7fc77ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import class_names\n",
    "\n",
    "\n",
    "h = open('/home/davidva/datasets/imagenet_vid_ytbb_robust/imagenet-vid-robust/misc/wnid_map.json')\n",
    "wnid_map = json.load(h)\n",
    "\n",
    "lll = []\n",
    "for class_name in class_names.all_wnids:\n",
    "    lll.append(True if class_name in wnid_map.keys() else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1fbc6a6-71b5-4f29-98da-99794c8e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define device, batch size and directory path for ImageNet validation set\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    base_exp_dir = '/home/davidva/experiments_David'\n",
    "\n",
    "    # Define the batch size\n",
    "    batch_size = 128\n",
    "\n",
    "    # Load imagenet labels as real classes\n",
    "    imagenet_labels = load_imagenet_labels()  # 'tench', 'goldfish', 'great white shark', 'tiger shark', 'hammerhead shark'...\n",
    "\n",
    "    data_names = ['imagenetv2-matched-frequency-format-val', 'imagenetv2-threshold0.7-format-val', 'imagenetv2-top-images-format-val', 'imagenetsketch/sketch', 'imagenet-r', 'imagenet-a', 'imagenet']\n",
    "    data_names = ['imagenetsketch']\n",
    "\n",
    "    for data_name in data_names:\n",
    "        if data_name in ['imagenet', 'imagenetv2-matched-frequency-format-val', 'imagenetv2-threshold0.7-format-val', 'imagenetv2-top-images-format-val', 'imagenetsketch']:\n",
    "            ds_specific_mask = [True] * 1000\n",
    "            ds_specific_labels = imagenet_labels  # the classes of the specific dataset that we're working with\n",
    "        elif data_name == 'imagenet-r':\n",
    "            ds_specific_r_mask = class_names.imagenet_r_mask\n",
    "            ds_specific_labels = class_names.imagenet_r_labels\n",
    "        elif data_name == 'imagenet-a':  # note: if the hidden file .ipynb_checkpoints is inside of the folder of the imagenet-a data,\n",
    "                                         # it should be removed from there in order to create the DataFolder object\n",
    "            ds_specific_mask = class_names.imagenet_a_mask\n",
    "            ds_specific_labels = class_names.imagenet_a_labels\n",
    "        elif data_name == 'imagenet_vid_robust':\n",
    "            ds_specific_mask = class_names.imagenet_vid_robust_mask\n",
    "            ds_specific_labels = class_names.imagenet_vid_robust_labels\n",
    "            f = open('/home/davidva/datasets/imagenet_vid_ytbb_robust/imagenet-vid-robust/misc/imagenet_vid_class_index.json')\n",
    "            vid_class_index_to_nid = json.load(f)  # converts class index (between 0 to 29) to imagenet-vid-robust nid (e.g. n029...)\n",
    "            g = open('/home/davidva/datasets/imagenet_vid_ytbb_robust/imagenet-vid-robust/misc/rev_wnid_map.json')\n",
    "            class_name_converter = json.load(g)  # converts imagenet-vid-robust nid to a list of imagenet nids\n",
    "        \n",
    "        if data_name == 'imagenet':\n",
    "            val_dir = '/datasets/ImageNet/val/'\n",
    "        elif data_name == 'imagenetsketch':\n",
    "            val_dir = '/home/davidva/datasets/imagenetsketch/sketch'\n",
    "        else:\n",
    "            val_dir = '/home/davidva/datasets/' + data_name\n",
    "        print('data_name is: ' + data_name + ' and val_dir is: ' + val_dir)\n",
    "\n",
    "        model_names = ['mobilenet_v2', 'resnet50', 'resnet34']\n",
    "    \n",
    "        for model_name in model_names:\n",
    "            # Experiment name\n",
    "            curr_time = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "            exp_base_name = 'predict_' + data_name + '_' + model_name\n",
    "            exp_name = exp_base_name + '_' + curr_time\n",
    "            exp_dir = os.path.join(base_exp_dir, exp_name)\n",
    "            results_dir = os.path.join(exp_dir, 'results')\n",
    "            embed_dir = os.path.join(results_dir, 'val_embeddings')\n",
    "        \n",
    "            # Create experiment directory\n",
    "            os.makedirs(exp_dir, exist_ok=True)\n",
    "            os.makedirs(results_dir, exist_ok=True)\n",
    "            os.makedirs(embed_dir, exist_ok=True)\n",
    "                \n",
    "            # Load the ImageNet validation dataset with defined transformations\n",
    "            val_dataset = ImageFolder(val_dir, transform=preprocess_images_any_dataset(model_name))\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=5)\n",
    "    \n",
    "            # Load model\n",
    "            model = load_model(model_name).to(device)\n",
    "            model.eval()\n",
    "            \n",
    "            # Register the hook at the penultimate layer of the model\n",
    "            if model_name in ['mobilenet_v2']:\n",
    "                layer = model.classifier[0]\n",
    "            elif model_name in ['densenet121']:\n",
    "                layer = model.features   # model.features.norm5 sucks, features.denseblock3.denselayer24 is okay, features gives 1000-of-shape output, model.features.denseblock3.denselayer24.conv2 is okay\n",
    "            elif model_name in ['vgg16', 'vgg19']:\n",
    "                layer = model.classifier[-2]\n",
    "            else:\n",
    "                layer = model.avgpool\n",
    "            \n",
    "            # Prepare DataFrame to store results\n",
    "            results = []\n",
    "            total_correct = 0\n",
    "            batch_num = 0\n",
    "            all_entropies = np.empty([0])\n",
    "            all_means = np.empty([0])\n",
    "            all_variances = np.empty([0])\n",
    "            all_skewnesses = np.empty([0])\n",
    "            all_kurtosises = np.empty([0])\n",
    "            all_top5_entropies = np.empty([0])\n",
    "            all_top5_means = np.empty([0])\n",
    "            all_top5_variances = np.empty([0])\n",
    "            all_top5_skewnesses = np.empty([0])\n",
    "            all_top5_kurtosises = np.empty([0])\n",
    "    \n",
    "            # Disable gradients for faster inference\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (images, labels) in enumerate(tqdm(val_loader, desc=f\"Processing {exp_name}\")):\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "    \n",
    "                    handle = layer.register_forward_hook(get_embedding_hook(batch_idx, batch_size, embed_dir))\n",
    "    \n",
    "                    # Run forward pass through the model and calculate probabilities\n",
    "                    output = model(images)\n",
    "                    probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "                    probabilities = probabilities * torch.tensor(ds_specific_mask).to(device)  # using only the classes that are in both datasets\n",
    "        \n",
    "                    # Get top-5 predictions and confidences and some statistics\n",
    "                    top5_prob, top5_classes = torch.topk(probabilities, 5)\n",
    "                    _, _, top5_means, top5_variances, top5_skewnesses, top5_kurtosises = scipy.stats.describe(top5_prob.detach().cpu().numpy() , axis=1)\n",
    "                    all_top5_means = np.concatenate((all_top5_means, top5_means))\n",
    "                    all_top5_variances = np.concatenate((all_top5_variances, top5_variances))\n",
    "                    all_top5_skewnesses = np.concatenate((all_top5_skewnesses, top5_skewnesses))\n",
    "                    all_top5_kurtosises = np.concatenate((all_top5_kurtosises, top5_kurtosises))\n",
    "                    top5_entropies = scipy.stats.entropy(top5_prob.detach().cpu().numpy(), axis=1)\n",
    "                    all_top5_entropies = np.concatenate((all_top5_entropies, top5_entropies))\n",
    "                    \n",
    "                    _, _, means, variances, skewnesses, kurtosises = scipy.stats.describe(probabilities.detach().cpu().numpy() , axis=1)\n",
    "                    all_means = np.concatenate((all_means, means))\n",
    "                    all_variances = np.concatenate((all_variances, variances))\n",
    "                    all_skewnesses = np.concatenate((all_skewnesses, skewnesses))\n",
    "                    all_kurtosises = np.concatenate((all_kurtosises, kurtosises))\n",
    "                    entropies = scipy.stats.entropy(probabilities.detach().cpu().numpy(), axis=1)\n",
    "                    all_entropies = np.concatenate((all_entropies, entropies))\n",
    "        \n",
    "                    # Iterate over each image in the batch\n",
    "                    for i in range(len(images)):\n",
    "                        image_idx = batch_idx * batch_size + i\n",
    "                        image_path = val_dataset.imgs[i + batch_num * batch_size][0]\n",
    "                        # true_class = val_dataset.classes[labels[i].item()]\n",
    "                        true_class = ds_specific_labels[labels[i].item()]  # e.g. labels[i].item()=0. true_class=goldfish\n",
    "                        predictions = {\"image_path\": image_path,\n",
    "                                       \"true_class\": true_class,\n",
    "                                       \"embeddings_path\":  os.path.join(embed_dir, f\"{image_idx}_embeddings.npy\")}\n",
    "                        \n",
    "                        for j in range(5):\n",
    "                            # predictions[f\"top{j+1}_prediction_class\"] = val_dataset.classes[top5_classes[i, j].item()]\n",
    "                            prediction_class = imagenet_labels[top5_classes[i, j].item()]\n",
    "                            predictions[f\"top{j+1}_prediction_class\"] = prediction_class\n",
    "                            predictions[f\"top{j+1}_confidence\"] = top5_prob[i, j].item()\n",
    "\n",
    "                            # Check if top-1 prediction is correct\n",
    "                            if data_name == 'imagenet_vid_robust':\n",
    "                                if j == 0:\n",
    "                                    vid_robust_class_nid = vid_class_index_to_nid[str(labels[i].item())][0]  # e.g. 'n02419796'\n",
    "                                    ground_truth_classes = class_name_converter[vid_robust_class_nid] # e.g. ['n02422106', 'n02422699', 'n02423022']\n",
    "                                    if prediction_class in ground_truth_classes:\n",
    "                                        total_correct += 1\n",
    "                            elif j == 0 and prediction_class == true_class:\n",
    "                                total_correct += 1\n",
    "                        results.append(predictions)\n",
    "                    batch_num += 1\n",
    "                    handle.remove()  # Unregister the hook after processing the batch\n",
    "                    break\n",
    "                                \n",
    "            \n",
    "            # Convert results to DataFrame and save to CSV\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df.to_csv(os.path.join(results_dir, f\"full_val_predictions_{exp_base_name}.csv\"), index=False)\n",
    "        \n",
    "            # Calculate average and std of the top1 confidences across the val set2\n",
    "            avg_confidence = results_df[\"top1_confidence\"].mean()\n",
    "            std_confidence = results_df[\"top1_confidence\"].std()\n",
    "            accuracy = total_correct / len(val_dataset)\n",
    "            average_top5_mean = np.mean(all_top5_means)\n",
    "            average_top5_variance = np.mean(all_top5_variances)\n",
    "            average_top5_skewness = np.mean(all_top5_skewnesses)\n",
    "            average_top5_kurtosis = np.mean(all_top5_kurtosises)\n",
    "            average_top5_entropy = np.mean(all_top5_entropies)\n",
    "            average_mean = np.mean(all_means)\n",
    "            average_variance = np.mean(all_variances)\n",
    "            average_skewness = np.mean(all_skewnesses)\n",
    "            average_kurtosis = np.mean(all_kurtosises)\n",
    "            average_entropy = np.mean(all_entropies)\n",
    "            top2_grad_confidence = (results_df[\"top1_confidence\"] - results_df[\"top2_confidence\"]).mean()\n",
    "    \n",
    "            # Save average and std confidences in a new DataFrame and some more statistics\n",
    "            confidence_df = pd.DataFrame({\n",
    "                \"Accuracy\": [accuracy],\n",
    "                \"Average Confidence\": [avg_confidence],\n",
    "                \"Standard Deviation Confidence\": [std_confidence],\n",
    "                \"Average Entropy\": [average_entropy],\n",
    "                \"Average mean\": [average_mean],\n",
    "                \"Average variance\": [average_variance],\n",
    "                \"Average skewness\": [average_skewness],\n",
    "                \"Average kurtosis\": [average_kurtosis],\n",
    "                \"Average top5 Entropy\": [average_top5_entropy],\n",
    "                \"Average top5 mean\": [average_top5_mean],\n",
    "                \"Average top5 variance\": [average_top5_variance],\n",
    "                \"Average top5 skewness\": [average_top5_skewness],\n",
    "                \"Average top5 kurtosis\": [average_top5_kurtosis],\n",
    "                \"top2_grad_confidence\": [top2_grad_confidence]\n",
    "            })\n",
    "            confidence_df.to_csv(os.path.join(results_dir, f\"val_confidence_summary_{exp_base_name}.csv\"), index=False)\n",
    "    \n",
    "            # Handle embeddings\n",
    "            embeddings = np.array([np.load(file) for file in results_df['embeddings_path']])\n",
    "            # assuming embeddings is a 4D numpy array\n",
    "            embeddings = embeddings.reshape(embeddings.shape[0], -1)\n",
    "            print(embeddings)\n",
    "            print(embeddings.shape)\n",
    "            continue\n",
    "            average, covariance = calculate_activation_statistics(embeddings)\n",
    "            np.save(os.path.join(results_dir, 'embeddings_covariance.npy'), covariance)\n",
    "            np.save(os.path.join(results_dir, 'embeddings_average.npy'), average)\n",
    "            # np.save(os.path.join(results_dir, 'tot_embeddings_2D_np_array.npy'), embeddings)\n",
    "            \n",
    "            # Create a new DataFrame for embeddings\n",
    "            # df_embeddings = pd.DataFrame(*******, columns=np.arange(0, embeddings.shape[1]))\n",
    "            # df_embeddings['true_class'] = results_df['true_class']\n",
    "            # df_embeddings['predicted_class'] = results_df['top1_prediction_class']\n",
    "            # df_embeddings['image_path'] = results_df['image_path']\n",
    "            # # Save as CSV\n",
    "            # df_embeddings.to_csv(os.path.join(results_dir, f\"val_embeddings_2d_{exp_base_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51cb8608-441b-4b3c-8048-daebe08d39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_name is: imagenetsketch and val_dir is: /home/davidva/datasets/imagenetsketch/sketch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Processing predict_imagenetsketch_mobilenet_v2_22-07-2023_18-57-59:   0%|   | 0/398 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02671015 0.00171657 0.0460147  ... 0.         0.         0.        ]\n",
      " [0.         0.02037799 0.0677322  ... 0.         0.         0.        ]\n",
      " [0.41246688 0.0139725  0.39630803 ... 0.         0.35750774 0.01537326]\n",
      " ...\n",
      " [0.07032369 0.         0.6472685  ... 0.00488729 0.21846849 0.01720898]\n",
      " [0.         0.04267349 0.         ... 0.06296569 0.10565615 0.        ]\n",
      " [0.         0.         0.         ... 0.24524435 0.08623537 0.        ]]\n",
      "(128, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Processing predict_imagenetsketch_resnet50_22-07-2023_18-58-18:   0%|       | 0/398 [00:16<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07946252 0.00908436 0.11294913 ... 0.03491938 0.         0.3887446 ]\n",
      " [0.9069552  0.09604716 0.7782015  ... 0.07150039 0.         0.5465018 ]\n",
      " [1.0958493  0.09429942 0.06916237 ... 0.20279767 0.         0.5502091 ]\n",
      " ...\n",
      " [0.03972644 0.15649162 0.09300479 ... 0.01561494 0.08422109 0.1410367 ]\n",
      " [0.02537842 0.         0.11367818 ... 0.         0.         0.42014655]\n",
      " [0.01596968 0.14475392 0.07495753 ... 0.0291111  0.         0.        ]]\n",
      "(128, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davidva/miniconda3/envs/anaconda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Processing predict_imagenetsketch_resnet34_22-07-2023_18-58-35:   0%|       | 0/398 [00:18<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.653874   0.31201592 0.16038497 ... 1.0917758  0.3057381  0.21315517]\n",
      " [1.4613996  0.12096184 0.78954923 ... 6.0389     1.9267793  0.8895854 ]\n",
      " [1.2781454  2.9755695  0.6889137  ... 2.5450897  0.72125584 1.2295638 ]\n",
      " ...\n",
      " [0.07453956 0.18535359 0.35546103 ... 4.2711263  0.25953907 1.3707743 ]\n",
      " [0.33146438 1.0275772  0.5090131  ... 0.5566723  0.19399302 2.6344025 ]\n",
      " [0.3677118  1.3870504  0.5162372  ... 0.9433905  0.18702917 2.9107087 ]]\n",
      "(128, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb79cdb5-850e-4f96-9fe3-7eb11e7c41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 avgpool fc\n",
      "resnet18 avgpool fc\n",
      "resnet34 avgpool fc\n",
      "resnet101 avgpool fc\n",
      "resnet152 avgpool fc\n",
      "vgg16 avgpool classifier\n",
      "vgg19 avgpool classifier\n",
      "alexnet avgpool classifier\n",
      "resnext avgpool fc\n",
      "wide_resnet avgpool fc\n",
      "densenet121 features classifier\n",
      "googlenet dropout fc\n",
      "mobilenet_v2 features classifier\n"
     ]
    }
   ],
   "source": [
    "# for layer in k.children():\n",
    "#     print(layer)\n",
    "\n",
    "model_names = ['resnet50', 'resnet18', 'resnet34', 'resnet101', 'resnet152', 'vgg16', 'vgg19', 'alexnet', 'resnext', 'wide_resnet', 'densenet121', 'googlenet', 'mobilenet_v2']\n",
    "\n",
    "for model_name in model_names:\n",
    "    k = load_model(model_name)\n",
    "    layers_list = []\n",
    "    for name, _ in k.named_children():\n",
    "        if not name.startswith('params'):\n",
    "            layers_list.append(name)\n",
    "    \n",
    "    print(model_name, layers_list[-2], layers_list[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
